{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Processing and Financial Sentiment Extraction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we would like to clean the raw news CSV file and use the processed news data for financial sentiment extraction using the FinBert model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip Install Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:47:04.005471Z",
     "start_time": "2024-05-20T22:46:56.064886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: demoji in /home/shartil/.local/lib/python3.10/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: contractions in /home/shartil/.local/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/shartil/.local/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /home/shartil/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: anyascii in /home/shartil/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install demoji\n",
    "%pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:47:12.665422Z",
     "start_time": "2024-05-20T22:47:04.008726Z"
    }
   },
   "outputs": [],
   "source": [
    "import demoji\n",
    "import contractions\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Const Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:47:12.676453Z",
     "start_time": "2024-05-20T22:47:12.669107Z"
    }
   },
   "outputs": [],
   "source": [
    "DATE_COLUMN_NAME = \"Date\"\n",
    "TIME_COLUMN_NAME = \"Time\"\n",
    "NEWS_COLUMN_NAME = \"Tweet\"\n",
    "LEFTOVER_COLUMN_NAME = \"Leftover\"\n",
    "\n",
    "NEWS_COLUMNS_LIST = [\n",
    "    DATE_COLUMN_NAME,\n",
    "    NEWS_COLUMN_NAME,\n",
    "    LEFTOVER_COLUMN_NAME\n",
    "]\n",
    "\n",
    "RAW_AMPERSAND_VALUE = \"&amp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_data(time_stamp):\n",
    "    # get date data by space split\n",
    "    date = time_stamp.split(\" \")[0]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_data(time_stamp):\n",
    "    # get date data by space and plus split\n",
    "    time_stamp = time_stamp.split(\" \")[1]\n",
    "    time = time_stamp.split(\"+\")[0]\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_raw_ampersand_value(text):\n",
    "    # replace &amp with &\n",
    "    text = text.replace(RAW_AMPERSAND_VALUE, \"&\")\n",
    "\n",
    "    # replace &; with &\n",
    "    text = text.replace(\"&;\", \"&\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_news_leftover(row):\n",
    "    news_separator = \"\"\n",
    "    current_news_data = row[NEWS_COLUMN_NAME]\n",
    "    amp_flag = RAW_AMPERSAND_VALUE in current_news_data\n",
    "\n",
    "    if pd.notna(row[LEFTOVER_COLUMN_NAME]):\n",
    "        if amp_flag:\n",
    "            current_news_data = replace_raw_ampersand_value(\n",
    "                current_news_data)\n",
    "            \n",
    "            # concat news data together without space\n",
    "            news_separator = \"\"\n",
    "\n",
    "        # concat news and leftover data together\n",
    "        leftover_data = row[LEFTOVER_COLUMN_NAME]\n",
    "        current_news_data += f\"{news_separator}{leftover_data}\"\n",
    "    \n",
    "    return current_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_news_data(news_data):\n",
    "    # delete any new lines and use only the first main title\n",
    "    news_data = news_data.split(\"\\n\")[0]\n",
    "\n",
    "    # delete any links for news data\n",
    "    news_data = news_data.split(\"http\")[0]\n",
    "\n",
    "    # delete any emoji characters\n",
    "    news_data = demoji.replace(news_data, repl=\"\")\n",
    "    \n",
    "    news_data = replace_raw_ampersand_value(news_data)\n",
    "    \n",
    "    # expend contractions in news data\n",
    "    news_data = contractions.fix(news_data, slang=False)\n",
    "    \n",
    "    # delete any spaces at the start or end of the news data\n",
    "    news_data = news_data.strip()\n",
    "\n",
    "    return news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading news dataframe and deleting any columns that are not Date or news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"../Data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_column in news_df.columns:\n",
    "    if current_column not in NEWS_COLUMNS_LIST:\n",
    "        news_df = news_df.drop(current_column, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Date data to separate Date and Time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new column for the time\n",
    "news_df[TIME_COLUMN_NAME] = news_df[DATE_COLUMN_NAME].apply(\n",
    "    get_time_data)\n",
    "\n",
    "# amend existing date column\n",
    "news_df[DATE_COLUMN_NAME] = news_df[DATE_COLUMN_NAME].apply(\n",
    "    get_date_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[NEWS_COLUMN_NAME] = news_df[NEWS_COLUMN_NAME].apply(\n",
    "    process_news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating misaligned news data with the main news column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[NEWS_COLUMN_NAME] = news_df.apply(\n",
    "    merge_news_leftover, \n",
    "    axis=1)\n",
    "\n",
    "news_df = news_df.drop(LEFTOVER_COLUMN_NAME, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[NEWS_COLUMN_NAME] = news_df[NEWS_COLUMN_NAME].apply(\n",
    "    process_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>Tesla to open a new Megafactory in Shanghai, C...</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>#5things: China holds military drills around T...</td>\n",
       "      <td>00:06:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>WATCH: Tesla Chief Executive Elon Musk is maki...</td>\n",
       "      <td>22:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>Teslaâ€™s Model S and X are starting to show the...</td>\n",
       "      <td>21:41:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>How the marketâ€™s biggest companies, from Apple...</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Tweet      Time\n",
       "0  2023-04-10  Tesla to open a new Megafactory in Shanghai, C...  01:00:00\n",
       "1  2023-04-10  #5things: China holds military drills around T...  00:06:05\n",
       "2  2023-04-09  WATCH: Tesla Chief Executive Elon Musk is maki...  22:10:00\n",
       "3  2023-04-09  Teslaâ€™s Model S and X are starting to show the...  21:41:02\n",
       "4  2023-04-09  How the marketâ€™s biggest companies, from Apple...  20:00:00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv(\"../Data/processed_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Sentiment Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip Install Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/shartil/.local/lib/python3.10/site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: networkx in /home/shartil/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: filelock in /home/shartil/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/shartil/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/shartil/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/shartil/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/shartil/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/shartil/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/shartil/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/shartil/.local/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: filelock in /home/shartil/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shartil/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/shartil/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shartil/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from enum import Enum\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Const Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_COLUMN_NAME = \"Sentiment\"\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    POSITIVE = 0\n",
    "    NEGATIVE = 1\n",
    "    NEUTRAL  = 2\n",
    "\n",
    "TOKENIZER = BertTokenizer.from_pretrained(\n",
    "    'ProsusAI/finbert')\n",
    "\n",
    "MODEL = BertForSequenceClassification.from_pretrained(\n",
    "    'ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_from_date(news_df, date):\n",
    "    return news_df[news_df[DATE_COLUMN_NAME].astype(str) == date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_probabilities(news_data):\n",
    "    # tokenize input\n",
    "    inputs = TOKENIZER(news_data, \n",
    "                       return_tensors='pt', \n",
    "                       truncation=True, \n",
    "                       padding=True)\n",
    "\n",
    "    # perform prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = MODEL(**inputs)\n",
    "\n",
    "    # get logits and apply softmax to get probabilities\n",
    "    logits = outputs.logits\n",
    "    probabilities = softmax(logits, dim=1)\n",
    "\n",
    "    # convert pytorch tensor to numpy array\n",
    "    return probabilities.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(date):\n",
    "    sentiment_category = 0\n",
    "    psitive_sentiment_avg = 0\n",
    "    negative_sentiment_avg = 0\n",
    "\n",
    "    # get news from given date\n",
    "    date_news = get_news_from_date(news_df, date)\n",
    "    amount_of_news = len(date_news)\n",
    "\n",
    "    # in case no news were published on given date, return 0\n",
    "    if amount_of_news == 0:\n",
    "        return sentiment_category\n",
    "\n",
    "    for i in range(amount_of_news):\n",
    "        current_news = date_news[NEWS_COLUMN_NAME].iloc[i]\n",
    "        sentiment_probabilities = get_sentiment_probabilities(\n",
    "            current_news)\n",
    "        \n",
    "        # sum positive probability\n",
    "        psitive_sentiment_avg += sentiment_probabilities[\n",
    "            Sentiment.POSITIVE.value]\n",
    "\n",
    "        # sum negative probability\n",
    "        negative_sentiment_avg += sentiment_probabilities[\n",
    "            Sentiment.NEGATIVE.value]\n",
    "\n",
    "    # calculate average of positive and negative probabilities sums  \n",
    "    psitive_sentiment_avg /= amount_of_news\n",
    "    negative_sentiment_avg /= amount_of_news\n",
    "    \n",
    "    # compare average values and assign sentiment category\n",
    "    if psitive_sentiment_avg > negative_sentiment_avg:\n",
    "        sentiment_category = 1\n",
    "    else:\n",
    "        sentiment_category = -1\n",
    "    \n",
    "    return sentiment_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading TESLA stock data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.508</td>\n",
       "      <td>4.778</td>\n",
       "      <td>4.778</td>\n",
       "      <td>93831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158</td>\n",
       "      <td>6.084</td>\n",
       "      <td>4.660</td>\n",
       "      <td>4.766</td>\n",
       "      <td>4.766</td>\n",
       "      <td>85935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.054</td>\n",
       "      <td>4.392</td>\n",
       "      <td>4.392</td>\n",
       "      <td>41094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.840</td>\n",
       "      <td>3.840</td>\n",
       "      <td>25699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.166</td>\n",
       "      <td>3.222</td>\n",
       "      <td>3.222</td>\n",
       "      <td>34334500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Open   High    Low  Close  Adj Close    Volume\n",
       "0  2010-06-29  3.800  5.000  3.508  4.778      4.778  93831500\n",
       "1  2010-06-30  5.158  6.084  4.660  4.766      4.766  85935500\n",
       "2  2010-07-01  5.000  5.184  4.054  4.392      4.392  41094000\n",
       "3  2010-07-02  4.600  4.620  3.742  3.840      3.840  25699000\n",
       "4  2010-07-06  4.000  4.000  3.166  3.222      3.222  34334500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_stock_df = pd.read_csv(\"../Data/TSLA.csv\")\n",
    "tesla_stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting sentiment score for each trading day in TESLA stock data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stock_df[SENTIMENT_COLUMN_NAME] = tesla_stock_df[DATE_COLUMN_NAME].apply(get_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the processed TESLA stock data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stock_df.to_csv(\"../Data/processed_TSLA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a5cfde8991b0f64e8bcd60a397bea8dc10ed042aefe1441fd3daa2ae2091421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
